{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import treebank, brown\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55907\n",
      "12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "test_corpus = brown.tagged_sents(tagset='universal')[-100:]\n",
    "\n",
    "tag_dict = {}\n",
    "word_dict = {}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag = elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]= 0\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag] = 0\n",
    "\n",
    "        word_dict[w] += 1\n",
    "        tag_dict[tag] += 1\n",
    "\n",
    "print(len(word_dict))\n",
    "print(len(tag_dict))\n",
    "        \n",
    "test_data = brown.tagged_sents(tagset='universal')[-10:]\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "k = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0.08901118099231307,\n",
       " 'ADJ': 0.0343466107617051,\n",
       " 'ADP': 0.12283368273934311,\n",
       " 'ADV': 0.09117749825296995,\n",
       " 'CONJ': 0.04916142557651992,\n",
       " 'DET': 0.21339972047519218,\n",
       " 'NOUN': 0.14129979035639412,\n",
       " 'NUM': 0.016788958770090845,\n",
       " 'PRON': 0.15971348707197763,\n",
       " 'PRT': 0.03665269042627533,\n",
       " 'VERB': 0.045090845562543676,\n",
       " 'X': 0.0005241090146750524}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Start Dict\n",
    "\n",
    "ind_tag = []\n",
    "tag_ind = {}\n",
    "start_matrix = {}\n",
    "\n",
    "for tag in tag_dict:\n",
    "    ind_tag += [tag]\n",
    "\n",
    "for ind, tag in enumerate(ind_tag):\n",
    "    tag_ind[tag] = ind\n",
    "\n",
    "start_tag_counts = {}\n",
    "total_sentences = 0\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        start_tag_counts[elem[1]] = start_tag_counts.get(elem[1], 0) + 1\n",
    "        break\n",
    "    total_sentences += 1\n",
    "\n",
    "for tag in tag_ind:\n",
    "    start_matrix[tag] = start_tag_counts[tag] / total_sentences\n",
    "start_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2696303799849e-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Emission Matrix\n",
    "\n",
    "tag_word_counts = {}\n",
    "emission_matrix = {}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        tag_word_counts[elem[1]] = tag_word_counts.get(elem[1], {})\n",
    "        tag_word_counts[elem[1]][elem[0]] = tag_word_counts[elem[1]].get(elem[0], 0)\n",
    "        tag_word_counts[elem[1]][elem[0]] += 1\n",
    "\n",
    "for tag in tag_dict:\n",
    "    emission_matrix[tag] = {}\n",
    "    for word in word_dict:\n",
    "        emission_matrix[tag][word] = (tag_word_counts[tag].get(word, 0) + k) / (k * len(word_dict) + tag_dict[tag])\n",
    "emission_matrix['NOUN']['tent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Transition Matrix\n",
    "\n",
    "tag_tag_count = {}\n",
    "transition_matrix = {}\n",
    "\n",
    "for sent in corpus:\n",
    "    for i in range(len(sent) - 1):\n",
    "        tag_tag_count[sent[i][1]] = tag_tag_count.get(sent[i][1], {})\n",
    "        tag_tag_count[sent[i][1]][sent[i + 1][1]] = tag_tag_count[sent[i][1]].get(sent[i + 1][1], 0)\n",
    "        tag_tag_count[sent[i][1]][sent[i + 1][1]] += 1\n",
    "\n",
    "for tag1 in tag_dict:\n",
    "    transition_matrix[tag1] = {}\n",
    "    for tag2 in tag_dict:\n",
    "        transition_matrix[tag1][tag2] = (tag_tag_count[tag1].get(tag2, 0) + k) / (k * len(tag_dict) + sum(tag_tag_count[tag1].values()))\n",
    "\n",
    "sum(transition_matrix['.'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-9-57fd79795455>(23)viterbi()\n",
      "-> path += [path_elem]\n",
      "(Pdb) backpointer[48]\n",
      "{'NUM': 'NOUN', 'NOUN': 'NOUN', 'ADP': 'NOUN', 'ADV': 'NOUN', '.': 'NOUN', 'PRON': 'NOUN', 'DET': 'NOUN', 'CONJ': 'NOUN', 'PRT': 'NOUN', 'ADJ': 'NOUN', 'VERB': 'NOUN', 'X': 'NOUN'}\n",
      "(Pdb) viterbi_dp[48]\n",
      "{'NUM': 9.904725719893204e-150, 'NOUN': 9.923302218817908e-150, 'ADP': 3.090798401487707e-149, 'ADV': 8.582428298276205e-150, '.': 1.7339057924548746e-141, 'PRON': 7.34638375812877e-150, 'DET': 2.071757897329409e-150, 'CONJ': 2.861708341942538e-149, 'PRT': 1.0931030354502221e-149, 'ADJ': 2.8184306720389313e-150, 'VERB': 1.5923347637040423e-149, 'X': 4.244276354143109e-150}\n"
     ]
    }
   ],
   "source": [
    "# Viterbi Algorithm\n",
    "\n",
    "def viterbi(sent):\n",
    "    viterbi_dp = {}\n",
    "    viterbi_dp[0] = {}\n",
    "    backpointer = {}\n",
    "    backpointer[0] = {}\n",
    "    \n",
    "    for tag in tag_dict:\n",
    "        viterbi_dp[0][tag] = start_matrix[tag] * emission_matrix[tag].get(sent[0][0], k / float(k * len(word_dict) + tag_dict[tag]))\n",
    "        backpointer[0][tag] = -1\n",
    "\n",
    "    for i, elem in enumerate(sent[1:], 1):\n",
    "        viterbi_dp[i] = {}\n",
    "        backpointer[i] = {}\n",
    "        for tag in tag_dict:\n",
    "            viterbi_dp[i][tag] = emission_matrix[tag].get(elem[0], k / float(k * len(word_dict) + tag_dict[tag])) * (max(transition_matrix[tag_before][tag] * viterbi_dp[i - 1][tag_before] for tag_before in tag_dict))\n",
    "            backpointer[i][tag] = max([[transition_matrix[tag_before][tag] * viterbi_dp[i - 1][tag_before], tag_before] for tag_before in tag_dict], key=lambda k: k[0])[1]\n",
    "    path, i = [], len(sent) - 1\n",
    "    while i != -1:\n",
    "        path_elem = max(backpointer[i], key=lambda k: backpointer[i][k])\n",
    "        pdb.set_trace()\n",
    "        path += [path_elem]\n",
    "        i -= 1\n",
    "    path.reverse()\n",
    "    print(path)\n",
    "    return path\n",
    "\n",
    "total = 0\n",
    "total_correct = 0\n",
    "\n",
    "for sent in test_corpus:\n",
    "    pred = viterbi(sent)\n",
    "    print(pred)\n",
    "    total_correct = sum([x == y[1] for x, y in zip(pred, sent)])\n",
    "    total += len(sent)\n",
    "\n",
    "print(total_correct / total * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
