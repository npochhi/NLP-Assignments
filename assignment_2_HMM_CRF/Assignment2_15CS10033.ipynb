{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import treebank, brown\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Neural Networks** - Discriminative, as Neural Networks are used to classify outputs i.e. assign probability given an input as opposed to compute a joint distribution og target variables.\n",
    "2. **Naive Bayes Classifier** - Generative, it may seem that Naive Bayes is discriminative as it models *p(y|X)*, but in doing so it utilizes *p(X, y)*. Hence Naive Bayes is generative.\n",
    "3. **Logistic Regression** - Discriminative, as it directly models *p(y|X)* as a function of X.\n",
    "4. **Gaussian Mixture Model** - Generative, in GMM, we model *p(X|y)* as a gaussian and hence, we are implicitly computing *p(X, y)* which is given as _p(y) * p(X|y)_.\n",
    "5. **GAN** - Both generative and discriminative, the generator part models input distribution whereas the discriminator tells whether the data is coming from *real* input distribution or from generator.\n",
    "6. **LDA** - Generative, as it models the documents and the words using a set of unboserved groups(topics)\n",
    "7. **SVM** - Discriminative, similar as logistic regression, optimization method is different and models *p(y|X)*.\n",
    "8. **Decision Trees** - Discriminative, in a decision tree, we directly model the true class label y given input x, by generating a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55907\n",
      "12\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "test_corpus = brown.tagged_sents(tagset='universal')[-100:]\n",
    "\n",
    "tag_dict = {}\n",
    "word_dict = {}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag = elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]= 0\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag] = 0\n",
    "\n",
    "        word_dict[w] += 1\n",
    "        tag_dict[tag] += 1\n",
    "\n",
    "print(len(word_dict))\n",
    "print(len(tag_dict))\n",
    "        \n",
    "test_data = brown.tagged_sents(tagset='universal')[-10:]\n",
    "\n",
    "print(len(test_data))\n",
    "\n",
    "k = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 0.08901118099231307,\n",
       " 'ADJ': 0.0343466107617051,\n",
       " 'ADP': 0.12283368273934311,\n",
       " 'ADV': 0.09117749825296995,\n",
       " 'CONJ': 0.04916142557651992,\n",
       " 'DET': 0.21339972047519218,\n",
       " 'NOUN': 0.14129979035639412,\n",
       " 'NUM': 0.016788958770090845,\n",
       " 'PRON': 0.15971348707197763,\n",
       " 'PRT': 0.03665269042627533,\n",
       " 'VERB': 0.045090845562543676,\n",
       " 'X': 0.0005241090146750524}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Start Dict\n",
    "\n",
    "ind_tag = []\n",
    "tag_ind = {}\n",
    "start_matrix = {}\n",
    "\n",
    "for tag in tag_dict:\n",
    "    ind_tag += [tag]\n",
    "\n",
    "for ind, tag in enumerate(ind_tag):\n",
    "    tag_ind[tag] = ind\n",
    "\n",
    "start_tag_counts = {}\n",
    "total_sentences = 0\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        start_tag_counts[elem[1]] = start_tag_counts.get(elem[1], 0) + 1\n",
    "        break\n",
    "    total_sentences += 1\n",
    "\n",
    "for tag in tag_ind:\n",
    "    start_matrix[tag] = start_tag_counts[tag] / total_sentences\n",
    "start_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.2696303799849e-05"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Emission Matrix\n",
    "\n",
    "tag_word_counts = {}\n",
    "emission_matrix = {}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        tag_word_counts[elem[1]] = tag_word_counts.get(elem[1], {})\n",
    "        tag_word_counts[elem[1]][elem[0]] = tag_word_counts[elem[1]].get(elem[0], 0)\n",
    "        tag_word_counts[elem[1]][elem[0]] += 1\n",
    "\n",
    "for tag in tag_dict:\n",
    "    emission_matrix[tag] = {}\n",
    "    for word in word_dict:\n",
    "        emission_matrix[tag][word] = (tag_word_counts[tag].get(word, 0) + k) / (k * len(word_dict) + tag_dict[tag])\n",
    "emission_matrix['NOUN']['tent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building Transition Matrix\n",
    "\n",
    "tag_tag_count = {}\n",
    "transition_matrix = {}\n",
    "\n",
    "for sent in corpus:\n",
    "    for i in range(len(sent) - 1):\n",
    "        tag_tag_count[sent[i][1]] = tag_tag_count.get(sent[i][1], {})\n",
    "        tag_tag_count[sent[i][1]][sent[i + 1][1]] = tag_tag_count[sent[i][1]].get(sent[i + 1][1], 0)\n",
    "        tag_tag_count[sent[i][1]][sent[i + 1][1]] += 1\n",
    "\n",
    "for tag1 in tag_dict:\n",
    "    transition_matrix[tag1] = {}\n",
    "    for tag2 in tag_dict:\n",
    "        transition_matrix[tag1][tag2] = (tag_tag_count[tag1].get(tag2, 0) + k) / (k * len(tag_dict) + sum(tag_tag_count[tag1].values()))\n",
    "\n",
    "sum(transition_matrix['.'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  92.27215455690886\n",
      "0 :\n",
      "[('you', 'PRON'), (\"can't\", 'VERB'), ('very', 'ADV'), ('well', 'ADV'), ('sidle', 'VERB'), ('up', 'ADP'), ('to', 'ADP'), ('people', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('street', 'NOUN'), ('and', 'CONJ'), ('ask', 'VERB'), ('if', 'ADP'), ('they', 'PRON'), ('want', 'VERB'), ('to', 'PRT'), ('buy', 'VERB'), ('a', 'DET'), ('hot', 'ADJ'), ('Bodhisattva', 'NOUN'), ('.', '.')]\n",
      "Prediction -  ['PRON', 'VERB', 'ADV', 'ADV', 'VERB', 'PRT', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'PRON', 'VERB', 'PRT', 'VERB', 'DET', 'ADJ', 'NOUN', '.']\n",
      "1 :\n",
      "[('Additionally', 'ADV'), (',', '.'), ('since', 'ADP'), (\"you're\", 'PRT'), ('going', 'VERB'), ('to', 'PRT'), ('be', 'VERB'), ('hors', 'X'), ('de', 'X'), ('combat', 'X'), ('pretty', 'ADV'), ('soon', 'ADV'), ('with', 'ADP'), ('sprue', 'NOUN'), (',', '.'), ('yaws', 'NOUN'), (',', '.'), ('Delhi', 'NOUN'), ('boil', 'NOUN'), (',', '.'), ('the', 'DET'), ('Granville', 'NOUN'), ('wilt', 'NOUN'), (',', '.'), ('liver', 'NOUN'), ('fluke', 'NOUN'), (',', '.'), ('bilharziasis', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('a', 'DET'), ('host', 'NOUN'), ('of', 'ADP'), ('other', 'ADJ'), ('complications', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('hex', 'NOUN'), (\"you've\", 'PRT'), ('aroused', 'VERB'), (',', '.'), ('you', 'PRON'), (\"mustn't\", 'VERB'), ('expect', 'VERB'), ('to', 'PRT'), ('be', 'VERB'), ('lionized', 'VERB'), ('socially', 'ADV'), ('.', '.')]\n",
      "Prediction -  ['ADV', '.', 'ADP', 'PRT', 'VERB', 'PRT', 'VERB', 'X', 'X', 'VERB', 'ADV', 'ADV', 'ADP', 'NOUN', '.', 'X', '.', 'NOUN', 'NOUN', '.', 'DET', 'NOUN', 'VERB', '.', 'NOUN', '.', '.', 'X', '.', 'CONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'PRT', 'VERB', '.', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'VERB', 'ADV', '.']\n",
      "2 :\n",
      "[('My', 'DET'), ('advice', 'NOUN'), (',', '.'), ('if', 'ADP'), ('you', 'PRON'), ('live', 'VERB'), ('long', 'ADJ'), ('enough', 'ADV'), ('to', 'PRT'), ('continue', 'VERB'), ('your', 'DET'), ('vocation', 'NOUN'), (',', '.'), ('is', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('next', 'ADJ'), ('time', 'NOUN'), (\"you're\", 'PRT'), ('attracted', 'VERB'), ('by', 'ADP'), ('the', 'DET'), ('exotic', 'ADJ'), (',', '.'), ('pass', 'VERB'), ('it', 'PRON'), ('up', 'PRT'), ('--', '.'), (\"it's\", 'PRT'), ('nothing', 'NOUN'), ('but', 'CONJ'), ('a', 'DET'), ('headache', 'NOUN'), ('.', '.')]\n",
      "Prediction -  ['DET', 'NOUN', '.', 'ADP', 'PRON', 'VERB', 'ADV', 'ADV', 'PRT', 'VERB', 'DET', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'PRT', 'VERB', 'ADP', 'DET', 'ADJ', '.', 'VERB', 'PRON', 'PRT', '.', 'PRT', 'NOUN', 'CONJ', 'DET', 'NOUN', '.']\n",
      "3 :\n",
      "[('As', 'ADP'), ('you', 'PRON'), ('can', 'VERB'), ('count', 'VERB'), ('on', 'ADP'), ('me', 'PRON'), ('to', 'PRT'), ('do', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('.', '.')]\n",
      "Prediction -  ['ADP', 'PRON', 'VERB', 'VERB', 'ADP', 'PRON', 'PRT', 'VERB', 'DET', 'ADJ', '.']\n",
      "4 :\n",
      "[('Compassionately', 'ADV'), ('yours', 'PRON'), (',', '.')]\n",
      "Prediction -  ['CONJ', 'PRON', '.']\n",
      "5 :\n",
      "[('S.', 'NOUN'), ('J.', 'NOUN'), ('Perelman', 'NOUN')]\n",
      "Prediction -  ['NOUN', 'NOUN', '.']\n",
      "6 :\n",
      "[('revulsion', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('desert', 'NOUN')]\n",
      "Prediction -  ['NOUN', 'ADP', 'DET', 'NOUN']\n",
      "7 :\n",
      "[('the', 'DET'), ('doors', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('D', 'NOUN'), ('train', 'NOUN'), ('slid', 'VERB'), ('shut', 'VERB'), (',', '.'), ('and', 'CONJ'), ('as', 'ADP'), ('I', 'PRON'), ('dropped', 'VERB'), ('into', 'ADP'), ('a', 'DET'), ('seat', 'NOUN'), ('and', 'CONJ'), (',', '.'), ('exhaling', 'VERB'), (',', '.'), ('looked', 'VERB'), ('up', 'PRT'), ('across', 'ADP'), ('the', 'DET'), ('aisle', 'NOUN'), (',', '.'), ('the', 'DET'), ('whole', 'ADJ'), ('aviary', 'NOUN'), ('in', 'ADP'), ('my', 'DET'), ('head', 'NOUN'), ('burst', 'VERB'), ('into', 'ADP'), ('song', 'NOUN'), ('.', '.')]\n",
      "Prediction -  ['DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'ADP', 'PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'CONJ', '.', 'X', '.', 'VERB', 'PRT', 'ADP', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'NOUN', '.']\n",
      "8 :\n",
      "[('She', 'PRON'), ('was', 'VERB'), ('a', 'DET'), ('living', 'VERB'), ('doll', 'NOUN'), ('and', 'CONJ'), ('no', 'DET'), ('mistake', 'NOUN'), ('--', '.'), ('the', 'DET'), ('blue-black', 'ADJ'), ('bang', 'NOUN'), (',', '.'), ('the', 'DET'), ('wide', 'ADJ'), ('cheekbones', 'NOUN'), (',', '.'), ('olive-flushed', 'ADJ'), (',', '.'), ('that', 'PRON'), ('betrayed', 'VERB'), ('the', 'DET'), ('Cherokee', 'NOUN'), ('strain', 'NOUN'), ('in', 'ADP'), ('her', 'DET'), ('Midwestern', 'ADJ'), ('lineage', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('the', 'DET'), ('mouth', 'NOUN'), ('whose', 'DET'), ('only', 'ADJ'), ('fault', 'NOUN'), (',', '.'), ('in', 'ADP'), ('the', 'DET'), (\"novelist's\", 'NOUN'), ('carping', 'VERB'), ('phrase', 'NOUN'), (',', '.'), ('was', 'VERB'), ('that', 'ADP'), ('the', 'DET'), ('lower', 'ADJ'), ('lip', 'NOUN'), ('was', 'VERB'), ('a', 'DET'), ('trifle', 'NOUN'), ('too', 'ADV'), ('voluptuous', 'ADJ'), ('.', '.')]\n",
      "Prediction -  ['PRON', 'VERB', 'DET', 'NOUN', 'NOUN', 'CONJ', 'DET', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', '.', 'X', '.', 'PRON', 'VERB', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'CONJ', 'DET', 'NOUN', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', 'DET', 'NOUN', 'ADV', 'ADJ', '.']\n",
      "9 :\n",
      "[('From', 'ADP'), ('what', 'DET'), ('I', 'PRON'), ('was', 'VERB'), ('able', 'ADJ'), ('to', 'ADP'), ('gauge', 'NOUN'), ('in', 'ADP'), ('a', 'DET'), ('swift', 'ADJ'), (',', '.'), ('greedy', 'ADJ'), ('glance', 'NOUN'), (',', '.'), ('the', 'DET'), ('figure', 'NOUN'), ('inside', 'ADP'), ('the', 'DET'), ('coral-colored', 'ADJ'), ('boucle', 'NOUN'), ('dress', 'NOUN'), ('was', 'VERB'), ('stupefying', 'VERB'), ('.', '.')]\n",
      "Prediction -  ['ADP', 'DET', 'PRON', 'VERB', 'ADJ', 'ADP', 'NOUN', 'ADP', 'DET', 'ADJ', '.', 'ADJ', 'NOUN', '.', 'DET', 'NOUN', 'ADP', 'DET', 'X', 'X', 'NOUN', 'VERB', 'ADV', '.']\n"
     ]
    }
   ],
   "source": [
    "# Viterbi Algorithm\n",
    "\n",
    "def viterbi(sent):\n",
    "    viterbi_dp = {}\n",
    "    viterbi_dp[0] = {}\n",
    "    backpointer = {}\n",
    "    backpointer[0] = {}\n",
    "    \n",
    "    for tag in tag_dict:\n",
    "        viterbi_dp[0][tag] = start_matrix[tag] * emission_matrix[tag].get(sent[0][0], k / float(k * len(word_dict) + tag_dict[tag]))\n",
    "        backpointer[0][tag] = -1\n",
    "\n",
    "    for i, elem in enumerate(sent[1:], 1):\n",
    "        viterbi_dp[i] = {}\n",
    "        backpointer[i] = {}\n",
    "        for tag in tag_dict:\n",
    "            viterbi_dp[i][tag] = emission_matrix[tag].get(elem[0], k / float(k * len(word_dict) + tag_dict[tag])) * (max(transition_matrix[tag_before][tag] * viterbi_dp[i - 1][tag_before] for tag_before in tag_dict))\n",
    "            backpointer[i][tag] = max([[transition_matrix[tag_before][tag] * viterbi_dp[i - 1][tag_before], tag_before] for tag_before in tag_dict], key=lambda k: k[0])[1]\n",
    "    i = len(sent) - 1\n",
    "    best_state_pointer = max(viterbi_dp[i], key=viterbi_dp[i].get)\n",
    "    path = [best_state_pointer]\n",
    "    while i != -1:\n",
    "        path += [backpointer[i][best_state_pointer]]\n",
    "        best_state_pointer = backpointer[i][best_state_pointer]\n",
    "        i -= 1\n",
    "    path.reverse()\n",
    "    return path\n",
    "\n",
    "total = 0\n",
    "total_correct = 0\n",
    "\n",
    "for sent in test_corpus:\n",
    "    pred = viterbi(sent)\n",
    "    total_correct += sum([x == y[1] for x, y in zip(pred[1:], sent)])\n",
    "    total += len(sent)\n",
    "\n",
    "print(\"Accuracy: \", total_correct / total * 100)\n",
    "    \n",
    "for i, sent in enumerate(test_data):\n",
    "    pred = viterbi(sent)\n",
    "    print(i, \":\")\n",
    "    print(sent)\n",
    "    print(\"Prediction - \", pred[1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install sklearn-crfsuite # install this please\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from nltk.tag.util import untag\n",
    "\n",
    "train_sents= corpus\n",
    "\n",
    "def word2features(sentence,index):\n",
    "    word = sentence[index]\n",
    "    \n",
    "    features ={\n",
    "        'bias': 1.0,\n",
    "        'word': sentence[index], #Justification - Obviously, word is going to be a feature\n",
    "        'is_first': index == 0, #Justification - Some words tend to occur more as a first word (like a, the etc.)\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0], #Justification- Nouns are more likely to start with capitalized letters\n",
    "        'is_all_caps': sentence[index][0].upper() == sentence[index][0], #Justification - Abbreviations generally have all caps and are generally nouns\n",
    "        'is_all_lower': sentence[index][0].lower() == sentence[index][0], #Justification - Would be not a proper noun\n",
    "        'prefix-1': sentence[index][0], #Justification - for capturing the stem of the word\n",
    "        'prefix-2': sentence[index][:2], #Justification - same as above\n",
    "        'prefix-3': sentence[index][:3], #Justification - same as above\n",
    "        'suffix-1': sentence[index][-1], #Justification - suffixes like 'y' is more common with Adjectives, etc\n",
    "        'suffix-2': sentence[index][-2:], #Justification - suffixes like 'al'(rebuttal) more common with Nouns and Adejctives(capable),etc\n",
    "        'suffix-3': sentence[index][-3:], #Justification - suffixes like 'ing' occur only in tags like Verbs, etc\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1], #Justification - There may be dependecies on the prev word\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1], #Justification - The next word becomes important in cases like of adjectives because if the next word is a Noun then it is more likely to be an adjective\n",
    "        'has_hyphen': '-' in sentence[index], #Justification - Hyphenated words are more likely to be Adjectives or Nouns and cannot be prepositions, conjunctions\n",
    "        'is_numeric': sentence[index][0].isdigit(), #Justification - Numbers can be identified using this feature(NUM tag)\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:] #Justification - Such words are usually proper nouns\n",
    "    }\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(untag(sent),i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_corpus]\n",
    "y_test=[sent2labels(s) for s in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=True, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95826906914597854"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          .      1.000     1.000     1.000       334\n",
      "          X      1.000     0.176     0.300        17\n",
      "        ADJ      0.881     0.900     0.890       140\n",
      "        ADP      0.968     0.975     0.972       283\n",
      "        ADV      0.901     0.879     0.890       124\n",
      "       VERB      0.975     0.941     0.957       370\n",
      "        DET      0.997     1.000     0.998       295\n",
      "       CONJ      1.000     0.988     0.994        84\n",
      "       NOUN      0.926     0.963     0.944       483\n",
      "       PRON      1.000     0.994     0.997       160\n",
      "        PRT      0.883     0.971     0.925        70\n",
      "        NUM      0.952     0.952     0.952        21\n",
      "\n",
      "avg / total      0.961     0.960     0.958      2381\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9601007979840404"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "for pred, real in zip(y_pred, y_test):\n",
    "    total_correct += sum([s1 == s2 for s1, s2 in zip(pred, real)])\n",
    "    total += len(pred)\n",
    "total_correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
